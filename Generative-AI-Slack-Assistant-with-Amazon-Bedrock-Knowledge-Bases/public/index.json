[
{
	"uri": "http://localhost:1313/",
	"title": "Building a Generative AI Slackbot Assistant with Amazon Bedrock",
	"tags": [],
	"description": "",
	"content": "Building a Generative AI Slackbot Assistant with Amazon Bedrock Quick Summary Build a production-ready Slack bot powered by Amazon Bedrock Knowledge Bases that intelligently answers questions about your organization\u0026rsquo;s documents using advanced AI and Retrieval-Augmented Generation (RAG).\nWhat you\u0026rsquo;ll create:\nAI-powered Slack bot with /ask-ai commands Enterprise-grade RAG system using Amazon Bedrock Secure content filtering with Bedrock Guardrails Scalable serverless architecture on AWS Duration Total Workshop Time: 3-4 hours\nModule Duration Focus Area Setup \u0026amp; Environment 45 min AWS configuration, Slack app creation Knowledge Base 75 min Document ingestion, vector database setup Bot Development 90 min Lambda functions, API Gateway integration Security \u0026amp; Testing 30 min Guardrails, validation, monitoring Target Audience 1. Primary Audience\nSolutions Architects looking to implement AI-powered assistants Developers interested in serverless AI applications DevOps Engineers deploying production AI systems Technical Leaders evaluating enterprise AI solutions 2. Secondary Audience\nProduct Managers understanding AI integration possibilities IT Professionals implementing workplace productivity tools Data Engineers working with unstructured data processing Prerequisite Knowledge 1. Required Skills\nAWS Fundamentals: Basic understanding of Lambda, S3, IAM, API Gateway Python Programming: Intermediate level (functions, APIs, error handling) REST APIs: Understanding of HTTP methods and JSON responses Command Line: Comfortable with terminal/command prompt operations 2. Helpful Background\nServerless Architecture: Experience with event-driven computing AI/ML Concepts: Basic understanding of embeddings and vector search Slack Development: Familiarity with Slack apps and webhooks Infrastructure as Code: Experience with CloudFormation or CDK 3. Technical Requirements\nAWS Account with administrative access Slack Workspace with app installation permissions Development Environment: Python 3.12+, AWS CLI, code editor Internet Connection: For downloading dependencies and accessing AWS services Cost Breakdown 1. Workshop Completion Cost: ~$5-10\nAWS Service Usage During Workshop Estimated Cost AWS Lambda 1,000 invocations $0.20 API Gateway 1,000 requests $3.50 Amazon Bedrock 100K tokens (Claude 3 + Titan) $3.00 OpenSearch Serverless 1 OCU × 4 hours $0.96 S3 Storage 10GB document storage $0.23 CloudWatch Logs Basic logging $0.50 2. Production Monthly Estimates\nSmall Team (10 users, 500 queries/month): ~$45\nMedium Team (50 users, 2,500 queries/month): ~$175\nLarge Team (200 users, 10,000 queries/month): ~$650\n3. Cost Optimization Tips\nUse OpenSearch Serverless auto-scaling Implement Lambda provisioned concurrency only if needed Monitor Bedrock token usage with CloudWatch Set up billing alerts for cost control Workshop Value Proposition 1. Immediate Benefits\nHands-on Experience with cutting-edge AWS AI services Production-Ready Code you can deploy in your organization Best Practices for enterprise AI implementation Security Patterns for responsible AI deployment 2. Long-term Skills\nRAG Architecture design and implementation Serverless AI application development Enterprise Integration patterns for AI systems Cost Optimization strategies for AI workloads 3. Business Impact\nReduced Support Tickets through self-service knowledge access Improved Productivity with instant information retrieval Enhanced Collaboration through intelligent Slack integration Scalable Foundation for additional AI use cases "
},
{
	"uri": "http://localhost:1313/4-security/4.1-secret_manager/",
	"title": "Configure AWS Secrets Manager",
	"tags": [],
	"description": "",
	"content": "AWS Secrets Manager securely stores and manages your Slack bot credentials with encryption at rest and automatic rotation capabilities.\nAccess Secrets Manager Console Navigate to AWS Secrets Manager Console\nPrepare Slack Credentials Copy your Bot User OAuth Token from Slack (from Module 3.3):\nCreate Bot Token Secret Create a new secret for bot-token:\nClick Store a new secret Select Other type of secret Enter key-value pair: SLACK_BOT_TOKEN = your-bot-token-value Name: bot-token5\nCreated successfully\nSave the ARN\nGet Signing Secret Copy your Signing Secret from Slack app settings:\nCreate Signing Secret Create a new secret for signing-secret:\nClick Store a new secret Select Other type of secret Enter key-value pair: SLACK_SIGNING_SECRET = your-signing-secret-value Name: signing-secret5 Created successfully\nSave the ARN\nTip: Keep the secret names consistent (bot-token5 and signing-secret5) as they will be referenced in Parameter Store configuration.\nWhat\u0026rsquo;s Next Your Slack credentials are now securely stored in AWS Secrets Manager. Next, we\u0026rsquo;ll configure Parameter Store to enable runtime access to these secrets.\nContinue to: 4.2 Configure Systems Manager Parameter Store\n"
},
{
	"uri": "http://localhost:1313/7-lambda_implementation/7.1-lambda_role/",
	"title": "Create Lambda Execution Role",
	"tags": [],
	"description": "",
	"content": "This section guides you through creating an IAM role with the necessary permissions for your Lambda function to interact with Bedrock, Secrets Manager, and other AWS services.\nCreate IAM Role Create Base Role\nCreate a new IAM role named BedrockExecutionRole8888:\nTrusted entity: AWS Lambda Use case: Lambda Attach AWSLambdaBasicExecutionRole managed policy Add Custom Policy Create BedrockExecutionPolicy\nAdd a custom inline policy named BedrockExecutionPolicy:\nPolicy JSON Configuration\nUse the following JSON policy (replace placeholder values with your actual ARNs):\n{ \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Action\u0026#34;: [\u0026#34;bedrock:InvokeModel\u0026#34;], \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Resource\u0026#34;: \u0026#34;arn:aws:bedrock:us-east-1::foundation-model/anthropic.claude-3-sonnet-20240229-v1:0\u0026#34; }, { \u0026#34;Action\u0026#34;: [\u0026#34;bedrock:Retrieve\u0026#34;, \u0026#34;bedrock:RetrieveAndGenerate\u0026#34;], \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Resource\u0026#34;: \u0026#34;arn:aws:bedrock:us-east-1:YOUR-ACCOUNT-ID:knowledge-base/YOUR-KB-ID\u0026#34; }, { \u0026#34;Action\u0026#34;: [\u0026#34;ssm:GetParameter\u0026#34;], \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Resource\u0026#34;: [ \u0026#34;arn:aws:ssm:us-east-1:YOUR-ACCOUNT-ID:parameter/slack-bot/token\u0026#34;, \u0026#34;arn:aws:ssm:us-east-1:YOUR-ACCOUNT-ID:parameter/slack-bot/signing-secret\u0026#34; ] }, { \u0026#34;Action\u0026#34;: [\u0026#34;lambda:InvokeFunction\u0026#34;], \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Resource\u0026#34;: \u0026#34;arn:aws:lambda:us-east-1:YOUR-ACCOUNT-ID:function:slack-bedrock-bot\u0026#34; }, { \u0026#34;Action\u0026#34;: [\u0026#34;bedrock:ApplyGuardrail\u0026#34;], \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Resource\u0026#34;: \u0026#34;arn:aws:bedrock:us-east-1:YOUR-ACCOUNT-ID:guardrail/*\u0026#34; }, { \u0026#34;Action\u0026#34;: [\u0026#34;secretsmanager:GetSecretValue\u0026#34;], \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Resource\u0026#34;: [ \u0026#34;arn:aws:secretsmanager:us-east-1:YOUR-ACCOUNT-ID:secret:bot-token5-*\u0026#34;, \u0026#34;arn:aws:secretsmanager:us-east-1:YOUR-ACCOUNT-ID:secret:signing-secret5-*\u0026#34; ] } ] } Policy Permissions Explained 1. Core Permissions\nPermission Purpose Resource bedrock:InvokeModel Call Claude 3 Sonnet Foundation model ARN bedrock:Retrieve Query Knowledge Base Knowledge Base ARN bedrock:RetrieveAndGenerate Full RAG workflow Knowledge Base ARN ssm:GetParameter Access configuration Parameter Store ARNs lambda:InvokeFunction Self-invocation Lambda function ARN bedrock:ApplyGuardrail Content filtering Guardrail ARNs secretsmanager:GetSecretValue Access Slack credentials Secrets Manager ARNs 2. Required Replacements\nBefore using the policy, replace these placeholders:\nYOUR-ACCOUNT-ID: Your AWS account ID YOUR-KB-ID: Your Knowledge Base ID from Module 6 Update secret ARNs to match your actual secret names Important: Replace all placeholder values with your actual ARNs before creating the policy. Incorrect ARNs will cause permission errors.\nWhat\u0026rsquo;s Next Your Lambda execution role is now configured with the necessary permissions. Next, we\u0026rsquo;ll create the Lambda function that will use this role.\nContinue to: 7.2 Create and Configure Lambda Function\n"
},
{
	"uri": "http://localhost:1313/3-slack_app/3.1-create_slack_app/",
	"title": "Create slack app",
	"tags": [],
	"description": "",
	"content": "Navigate to Slack API Go to api.slack.com/apps and click Create New App → From scratch Configure App Details Fill in the app information: App Name: AWS AI Assistant Pick a workspace: Select your workshop workspace Click Create App Tip: Use a descriptive name like \u0026ldquo;AWS AI Assistant\u0026rdquo; to easily identify your bot in the workspace.\nWhat\u0026rsquo;s Next Your Slack app is now created! In the next section, we\u0026rsquo;ll configure the necessary permissions and settings to enable bot functionality.\nContinue to: 3.2 Create slash commands\n"
},
{
	"uri": "http://localhost:1313/1-introduction/",
	"title": "Introduction",
	"tags": [],
	"description": "",
	"content": "Introduction to Slackbot Assistant with Amazon Bedrock Welcome to this comprehensive workshop on building a Generative AI Slack Assistant with Amazon Bedrock Knowledge Bases! In this hands-on experience, you\u0026rsquo;ll learn to create an intelligent AI assistant that transforms how your organization accesses and utilizes knowledge, making information instantly available through natural language conversations in Slack.\nThe Challenge We\u0026rsquo;re Addressing Modern organizations face a critical productivity challenge: information silos. Valuable knowledge is scattered across documents, wikis, policies, and databases, making it difficult for employees to find answers quickly. Traditional search methods often fail to understand context and intent, leading to:\nTime waste searching through multiple documents Inconsistent answers from different team members Knowledge gaps when experts are unavailable Reduced productivity due to information friction Our Solution Approach This workshop demonstrates how to transform static organizational knowledge into an intelligent, conversational assistant that integrates seamlessly with existing workflows through Slack.\nWorkshop Objectives By completing this workshop, you will achieve the following learning outcomes:\nPrimary Objectives Master RAG Architecture\nUnderstand Retrieval-Augmented Generation principles Implement vector-based semantic search Design efficient document ingestion pipelines Build Production-Ready AI Systems\nDeploy scalable serverless architecture Implement proper error handling and monitoring Configure auto-scaling and cost optimization Integrate Enterprise Security\nConfigure Amazon Bedrock Guardrails Implement PII detection and anonymization Set up content filtering and safety measures Develop Slack Bot Applications\nUse Slack Bolt framework for Python Handle asynchronous message processing Implement proper authentication and permissions Technical Skills You\u0026rsquo;ll Gain Amazon Bedrock integration and model management OpenSearch Serverless vector database operations AWS Lambda serverless function development API Gateway REST API configuration Infrastructure as Code using AWS CDK Slack API development and webhook handling SlackBot Architecture Architecture Flow Diagram graph TB\rA[Slack User] --\u0026gt;|/ask-ai command| B[API Gateway]\rB --\u0026gt; C[Lambda Function]\rC --\u0026gt; D[Bedrock Knowledge Base]\rD --\u0026gt; E[OpenSearch Serverless]\rD --\u0026gt; F[Claude 3 Sonnet]\rG[S3 Documents] --\u0026gt;|Ingestion| D\rF --\u0026gt; H[Bedrock Guardrails]\rH --\u0026gt;|Filtered Response| I[Slack Channel]\rstyle A fill:#e1f5fe\rstyle D fill:#f3e5f5\rstyle F fill:#fff3e0\rstyle H fill:#ffebee Key Components Explained Component Purpose Benefits Slack Interface User interaction layer Familiar interface, no training required API Gateway HTTP endpoint management Secure, scalable API access Lambda Function Business logic processing Serverless, cost-effective compute Bedrock Knowledge Base RAG orchestration Fully managed, no infrastructure OpenSearch Serverless Vector storage and search Auto-scaling, semantic search Bedrock Guardrails Content safety and filtering Enterprise-grade security What You\u0026rsquo;ll Build 1. Intelligent Slack Assistant\nNatural Language Processing: Ask questions in plain English Contextual Responses: AI-powered answers with source citations Multi-Document Search: Query across your entire knowledge base Real-Time Processing: Sub-3-second response acknowledgment 2. Enterprise Security Features\nContent Filtering: Block inappropriate or harmful content PII Protection: Automatic detection and anonymization Prompt Injection Defense: Prevent malicious prompt manipulation Access Control: Workspace-based permissions 3. Production-Ready Infrastructure\nAuto-Scaling: Handle varying workloads automatically Monitoring: CloudWatch integration for observability Error Handling: Graceful degradation and user feedback Cost Optimization: Pay-per-use serverless model Real-World Applications This solution pattern enables numerous enterprise use cases:\n1. Customer Support\nInstant answers from product documentation Consistent responses across support teams Reduced ticket volume and response times 2. Human Resources\nEmployee self-service for policy questions Onboarding assistance and training materials Benefits and procedure clarification 3. Technical Documentation\nEngineering knowledge base access API documentation and troubleshooting guides Best practices and coding standards 4. Compliance \u0026amp; Legal\nRegulatory requirement queries Policy interpretation and guidance Audit preparation and documentation Technology Stack Deep Dive 1. Amazon Bedrock Ecosystem\nFoundation Models: Claude 3 Sonnet for text generation Embeddings: Titan Text Embeddings V2 for vector creation Knowledge Bases: Managed RAG workflow orchestration Guardrails: Content safety and filtering mechanisms 2. Supporting AWS Services\nLambda: Event-driven serverless compute API Gateway: RESTful API management S3: Document storage and versioning OpenSearch Serverless: Vector database operations CloudWatch: Logging, monitoring, and alerting Secrets Manager: Secure credential storage 3. Development Framework\nSlack Bolt for Python: Simplified bot development AWS CDK: Infrastructure as Code deployment Python 3.12+: Modern language features and performance Workshop Learning Path graph LR\rA[Setup \u0026amp; Prerequisites] --\u0026gt; B[Knowledge Base Foundation]\rB --\u0026gt; C[Bedrock Integration]\rC --\u0026gt; D[Slack Bot Development]\rD --\u0026gt; E[Security \u0026amp; Guardrails]\rE --\u0026gt; F[Production Deployment]\rF --\u0026gt; G[Testing \u0026amp; Validation] Success Metrics Upon workshop completion, you\u0026rsquo;ll have achieved:\n1. Functional Deliverables\nWorking Slack bot responding to natural language queries Deployed AWS infrastructure with proper security Integrated knowledge base with your documents Monitoring and alerting configuration 2. Measurable Outcomes\nResponse Time: \u0026lt; 3 seconds for query acknowledgment Accuracy: Relevant answers with source attribution Security: Zero inappropriate content in responses Scalability: Handle 100+ concurrent users 3. Knowledge Transfer\nUnderstanding of RAG architecture principles Hands-on experience with Amazon Bedrock services Production deployment best practices Enterprise AI security implementation Next Steps Now that you understand the workshop objectives and architecture, you\u0026rsquo;re ready to begin the hands-on implementation. The journey ahead will transform you from an AI curious professional to someone capable of deploying production-grade generative AI solutions.\nLet\u0026rsquo;s start building the future of workplace productivity!\nContinue to: Environment Setup\n"
},
{
	"uri": "http://localhost:1313/5-opensearch/5.1-collection/",
	"title": "OpenSearch Serverless Collection",
	"tags": [],
	"description": "",
	"content": "Create OpenSearch Serverless Collection This section guides you through creating an OpenSearch Serverless collection for vector storage, including the necessary access and network policies.\nAccess OpenSearch Console Navigate to Amazon OpenSearch Service Console\nCreate Data Access Policy Scroll down and select Data access policies → Create access policy\nEnter Access policy name → Choose JSON\nEnter the following JSON policy and click Create:\n[ { \u0026#34;Rules\u0026#34;: [ { \u0026#34;ResourceType\u0026#34;: \u0026#34;index\u0026#34;, \u0026#34;Resource\u0026#34;: [\u0026#34;index/slack-bedrock-vector-db/*\u0026#34;], \u0026#34;Permission\u0026#34;: [\u0026#34;aoss:*\u0026#34;] }, { \u0026#34;ResourceType\u0026#34;: \u0026#34;collection\u0026#34;, \u0026#34;Resource\u0026#34;: [\u0026#34;collection/slack-bedrock-vector-db\u0026#34;], \u0026#34;Permission\u0026#34;: [\u0026#34;aoss:*\u0026#34;] } ], \u0026#34;Principal\u0026#34;: [\u0026#34;arn:aws:iam::\u0026lt;YOUR-ACCOUNT-ID\u0026gt;:root\u0026#34;] } ] Important: Replace \u0026lt;YOUR-ACCOUNT-ID\u0026gt; with your actual AWS account ID.\nCreate Network Policy Create Network policy → Create network policy\nEnter Network policy name -\u0026gt; select JSON\nEnter the following JSON policy and click Create:\n[ { \u0026#34;Rules\u0026#34;: [ { \u0026#34;ResourceType\u0026#34;: \u0026#34;collection\u0026#34;, \u0026#34;Resource\u0026#34;: [\u0026#34;collection/slack-bedrock-vector-db\u0026#34;] }, { \u0026#34;ResourceType\u0026#34;: \u0026#34;dashboard\u0026#34;, \u0026#34;Resource\u0026#34;: [\u0026#34;collection/slack-bedrock-vector-db\u0026#34;] } ], \u0026#34;AllowFromPublic\u0026#34;: true } ] Create Vector Collection Create the collection:\nSelect Collections\nSelect Create Collection\nConfigure collection settings:\nCollection name: slack-bedrock-vector-db5 Collection type: Vector search\nSecurity: Standard create\nUse default settings and click Create\nNote Important Information Save the following details for later configuration:\nCollection ARN: arn:aws:aoss:us-east-1:account:collection/collection-id OpenSearch Endpoint: https://collection-id.us-east-1.aoss.amazonaws.com The next step is to create an index table.\nTip: Copy and save the Collection ARN and OpenSearch Endpoint as they will be needed for Bedrock Knowledge Base configuration.\nWhat\u0026rsquo;s Next Your OpenSearch Serverless collection is now ready to store vector embeddings. Next, we\u0026rsquo;ll create the vector index for efficient similarity searches.\nContinue to: 5.2 - Create Vector Index\n"
},
{
	"uri": "http://localhost:1313/6-bedrock_setup/6.1-model_access/",
	"title": "Setup Model Access",
	"tags": [],
	"description": "",
	"content": "Enable Foundation Model Access This section guides you through enabling access to the required Amazon Bedrock foundation models for your AI assistant.\nRequired Models For this workshop, you need access to:\nAmazon Titan Text Embeddings V2: For document vectorization Anthropic Claude 3 Sonnet: For intelligent text generation Access Bedrock Console Navigate to Amazon Bedrock Console\nNavigate to Model Access Scroll down to the bottom of the navigation sidebar and choose Model access\nModify Model Access Click Modify model access\nSelect Required Models Select the models needed for this workshop:\n✅ Amazon Titan Text Embeddings V2 ✅ Anthropic Claude 3 Sonnet Click Next to proceed\nSubmit Access Request Review your model selections and click Submit\nAccess requests are typically approved instantly for these models Wait a few minutes for the access to be granted Verify Model Access Confirm both models show Access granted status:\n✅ Amazon Titan Text Embeddings V2: Access granted ✅ Anthropic Claude 3 Sonnet: Access granted Tip: Model access is typically granted immediately for Titan and Claude models. If you encounter delays, ensure your AWS account is in good standing.\nWhat\u0026rsquo;s Next With foundation model access enabled, you\u0026rsquo;re ready to create the Knowledge Base that will power your AI assistant\u0026rsquo;s intelligent responses.\nContinue to: 6.2 Setup Guardrails\n"
},
{
	"uri": "http://localhost:1313/4-security/4.2-systems_manager/",
	"title": "Configure Systems Manager Parameter Store",
	"tags": [],
	"description": "",
	"content": "AWS Systems Manager Parameter Store provides runtime secret resolution by creating references to Secrets Manager, enabling Lambda functions to dynamically fetch credentials without direct access to secrets.\nAccess Parameter Store Navigate to AWS Systems Manager Console\nCreate Bot Token Parameter Create a parameter for bot-token5:\nClick Create parameter\nName: /slack/bot-token5/parameter5 Type: String Value: slack/bot-token5\nCreate successfully\nCreate Signing Secret Parameter Create a parameter for signing-secret5:\nClick Create parameter Name: /slack/signing-secret5/parameter5\nType: String Value: slack/signing-secret5\n-Create successfully\nNote Parameter ARNs Copy the Parameter ARNs for IAM policy configuration:\nSigning secret ARN: arn:aws:ssm:region:account:parameter/slack/signing-secret5/parameter5 Bot token ARN: arn:aws:ssm:region:account:parameter/slack/bot-token5/parameter5\nWhat\u0026rsquo;s Next Your Parameter Store is now configured to securely reference Secrets Manager. These parameters will be used by Lambda functions to access Slack credentials without direct secret exposure.\nContinue to: 5 OpenSearch Serverless\n"
},
{
	"uri": "http://localhost:1313/7-lambda_implementation/7.2-config_code/",
	"title": "Create and Configure Lambda Function",
	"tags": [],
	"description": "",
	"content": "This section guides you through creating the Lambda function and configuring it with the necessary code, settings, and environment variables.\nCreate Lambda Function Basic Function Setup\nCreate a new Lambda function named BedrockKBSlackbotFunction5:\nRuntime: Python 3.12 Architecture: x86_64 Attach IAM Role\nAttach the IAM role BedrockExecutionRole8888 (created in section 7.1) and click Create:\nUpload Function Code Deploy Code Package\nUpload the Lambda deployment package:\nDownload: BedrockKBSlackbotFunction.zip Go to Code tab → Upload from → .zip file Select and upload the downloaded zip file Select Save\nUpload successfully\nNote: The zip file contains the Slack Bolt framework and all necessary dependencies for the bot functionality.\nConfigure Function Settings Update Handler\nChange the Handler to match your code entry point:\nHandler: index.handler Adjust Performance Settings\nConfigure Memory and Timeout for optimal performance:\nMemory: 512 MB (recommended for Bedrock API calls) Timeout: 5 minutes (allows time for Knowledge Base queries) Environment Variables Add Configuration Variables\nAdd the following Environment variables:\nKey Value Purpose KNOWLEDGE_BASE_ID your-kb-id-from-module-6 References your Knowledge Base MODEL_ID anthropic.claude-3-sonnet-20240229-v1:0 Specifies text generation model SLACK_BOT_TOKEN_PARAMETER /slack/bot-token5/parameter5 Parameter Store path for bot token SLACK_SIGNING_SECRET_PARAMETER /slack-bot/signing-secret5/parameter5 Parameter Store path for signing secret AWS_REGION us-east-1 AWS region for service calls GUARDRAIL_ID your-guardrail-id References your guardrail SLACK_SLASH_COMMAND /ask-ai slash command created at the beginning Required Values\nReplace these placeholder values with your actual configuration:\nKNOWLEDGE_BASE_ID: Copy from your Bedrock Knowledge Base (Module 6.3) MODEL_ID: Use the exact Claude 3 Sonnet model ID shown above Parameter paths: Must match your Parameter Store configuration (Module 4.2) Important: Ensure all environment variable values match your actual AWS resources. Incorrect values will cause runtime errors.\nFunction Configuration Summary 1. Runtime Settings\n✅ Function name: BedrockKBSlackbotFunction5 ✅ Runtime: Python 3.12 ✅ Handler: lambda_function.lambda_handler ✅ Memory: 512 MB ✅ Timeout: 5 minutes 2. Security Settings\n✅ Execution role: BedrockExecutionRole8888 ✅ Environment variables: Configured with proper values ✅ Code package: Uploaded with dependencies What\u0026rsquo;s Next Your Lambda function is now configured and ready to process Slack commands. Next, we\u0026rsquo;ll create the API Gateway that will receive requests from Slack and trigger your Lambda function.\nContinue to: 8. API Gateway Integration and Complete Testing\n"
},
{
	"uri": "http://localhost:1313/3-slack_app/3.2-create_slash_commands/",
	"title": "Create slash commands",
	"tags": [],
	"description": "",
	"content": "Navigate to Slash Commands In your app settings, click Slash Commands → Create New Command Configure Command Details Fill in the command configuration:\nCommand: /ask-ai Request URL: https://www.google.com/ (temporary) Short Description:test bedrock Usage Hint: [your question about AWS] Note: The Request URL is temporary. We\u0026rsquo;ll update it with the actual API Gateway URL after deploying our AWS infrastructure.\nSave Command Click Save to create the slash command successfully What\u0026rsquo;s Next Your slash command is now configured! Next, we\u0026rsquo;ll set up the necessary OAuth permissions for your bot to function properly.\nContinue to: 3.3 - Get OAuth Tokens\n"
},
{
	"uri": "http://localhost:1313/5-opensearch/5.2-vector_index/",
	"title": "Create Vector Index",
	"tags": [],
	"description": "",
	"content": "This section guides you through creating a vector index in OpenSearch Serverless using Postman to enable k-NN similarity searches for your AI assistant.\nCreate IAM User Create Deployment User Create an IAM user bedrock-chatbot-deployer with AdministratorAccess policy\nGenerate Access Keys Create Access Keys for programmatic access: Get the access key information of the newly created user\nAdd a tag with Key and Value as an access key\nImportant: Save the Access Key ID and Secret Access Key securely - they will be needed for Postman authentication.\nConfigure Postman Request Set Up Authentication Open Postman and configure the request:\nMethod: PUT URL: \u0026lt;Opensearch-Endpoint\u0026gt;/slack-bedrock-os-index5 Auth Type: AWS Signature Access Key: Your IAM user access key Secret Key: Your IAM user secret key Region: us-east-1 Service Name: aoss Set Headers Configure request headers: Content-Type: application/json\nConfigure Request Body Set body type to raw and enter the following JSON:\n{ \u0026#34;settings\u0026#34;: { \u0026#34;index\u0026#34;: { \u0026#34;knn\u0026#34;: true, \u0026#34;knn.algo_param.ef_search\u0026#34;: 512 } }, \u0026#34;mappings\u0026#34;: { \u0026#34;properties\u0026#34;: { \u0026#34;bedrock-knowledge-base-default-vector\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;knn_vector\u0026#34;, \u0026#34;dimension\u0026#34;: 1024, \u0026#34;method\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;hnsw\u0026#34;, \u0026#34;engine\u0026#34;: \u0026#34;faiss\u0026#34;, \u0026#34;space_type\u0026#34;: \u0026#34;l2\u0026#34;, \u0026#34;parameters\u0026#34;: { \u0026#34;ef_construction\u0026#34;: 512, \u0026#34;m\u0026#34;: 16 } } }, \u0026#34;AMAZON_BEDROCK_METADATA\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;text\u0026#34;, \u0026#34;index\u0026#34;: false }, \u0026#34;AMAZON_BEDROCK_TEXT_CHUNK\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;text\u0026#34;, \u0026#34;index\u0026#34;: true }, \u0026#34;id\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;text\u0026#34;, \u0026#34;index\u0026#34;: true }, \u0026#34;x-amz-bedrock-kb-data-source-id\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;text\u0026#34;, \u0026#34;index\u0026#34;: true }, \u0026#34;x-amz-bedrock-kb-document-page-number\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;long\u0026#34;, \u0026#34;index\u0026#34;: true }, \u0026#34;x-amz-bedrock-kb-source-uri\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;text\u0026#34;, \u0026#34;index\u0026#34;: true } } } } Create the Index Send Request Click Send to create the vector index A successful response indicates the index was created\nVerify Index Creation Verify the index was created successfully in OpenSearch console:\nIndex Name: slack-bedrock-os-index5\nVector Field: bedrock-knowledge-base-default-vector\nMetadata Fields: Available for document tracking\nNote: The vector index is configured with 1024 dimensions to match Amazon Titan Text Embeddings V2 model output and uses HNSW algorithm for efficient similarity search.\nIndex Configuration Explained Vector Settings Dimension: 1024 (matches Titan Embeddings V2) Algorithm: HNSW (Hierarchical Navigable Small World) Engine: FAISS (Facebook AI Similarity Search) Space Type: L2 (Euclidean distance) Metadata Fields AMAZON_BEDROCK_TEXT_CHUNK: Searchable document text AMAZON_BEDROCK_METADATA: Document metadata (not indexed) x-amz-bedrock-kb-source-uri: Document source tracking x-amz-bedrock-kb-document-page-number: Page reference What\u0026rsquo;s Next Your vector index is now ready to store and search document embeddings. Next, we\u0026rsquo;ll create the Bedrock Knowledge Base that will use this OpenSearch collection.\nContinue to: 6 Bedrock Setup\n"
},
{
	"uri": "http://localhost:1313/2-environment-setup/",
	"title": "Environment Setup",
	"tags": [],
	"description": "",
	"content": "Environment Setup Overview Before building your Generative AI Slack Assistant, you need to set up the required environments and tools. This module will guide you through creating a Slack workspace, configuring AWS services, and preparing your development environment.\nPrerequisites Checklist Ensure you have the following before proceeding:\n✅ AWS Account with administrative access ✅ Email address for Slack workspace creation ✅ Python 3.12+ installed on your local machine ✅ AWS CLI installed and configured ✅ Code editor (VS Code recommended) Module Learning Objectives By the end of this module, you will have:\nCreated a Slack workspace for testing the bot Configured AWS CLI with proper credentials Enabled Amazon Bedrock models in your AWS account Set up your development environment with required dependencies Verified all prerequisites for the workshop Create Slack Workspace 1. Navigate to Slack\nGo to Slack.com and click Create a new workspace.\n2. Sign Up Process\nEnter your email to sign in 3. Click Create a Workspace\nComplete Workspace Setup 1. Complete the workspace creation process by providing:\nWorkspace name (e.g., \u0026ldquo;AI-Assistant-Workshop\u0026rdquo;) Channel name (e.g., \u0026ldquo;#ai-assistant\u0026rdquo;) Team member invitations (optional for workshop) Tip: Keep your workspace name simple and related to the workshop. You\u0026rsquo;ll use this workspace to test your AI assistant.\nAWS Account Configuration 1. Verify AWS Account Access\nLog in to AWS Console\nNavigate to AWS Console Ensure you have administrative access or the following permissions: Amazon Bedrock full access Lambda full access API Gateway full access S3 full access OpenSearch Serverless access 2. Configure AWS CLI\nInstall AWS CLI (if not already installed)\n# Windows msiexec.exe /i https://awscli.amazonaws.com/AWSCLIV2.msi # macOS curl \u0026#34;https://awscli.amazonaws.com/AWSCLIV2.pkg\u0026#34; -o \u0026#34;AWSCLIV2.pkg\u0026#34; sudo installer -pkg AWSCLIV2.pkg -target / # Linux curl \u0026#34;https://awscli.amazonaws.com/awscli-exe-linux-x86_64.zip\u0026#34; -o \u0026#34;awscliv2.zip\u0026#34; unzip awscliv2.zip sudo ./aws/install 3. Configure AWS credentials\naws configure Enter the following when prompted:\nAWS Access Key ID: Your access key AWS Secret Access Key: Your secret key Default region name: us-east-1 (recommended for Bedrock) Default output format: json 4. Verify configuration\naws sts get-caller-identity Important: Use us-east-1 region for this workshop as it has the best model availability for Amazon Bedrock.\nTroubleshooting Common Issues AWS CLI Issues\nProblem: aws: command not found Solution: Restart terminal after installation or add AWS CLI to PATH Need Help? If you encounter issues, check the Troubleshooting Guide or ask the workshop instructor.\nNext Steps With your environment properly configured, you\u0026rsquo;re ready to start building the knowledge base foundation for your AI assistant.\nContinue to: Slack App Setup\nSummary In this module, you have:\n✅ Created a Slack workspace for testing ✅ Configured AWS CLI and verified access Your development environment is now ready for building the Generative AI Slack Assistant!\n"
},
{
	"uri": "http://localhost:1313/6-bedrock_setup/6.2-guardrails/",
	"title": "Setup Guardrails",
	"tags": [],
	"description": "",
	"content": "Amazon Bedrock Guardrails Overview Amazon Bedrock Guardrails help you implement safeguards for your generative AI applications by filtering harmful content, blocking unwanted topics, and removing sensitive information. This ensures your Slack AI assistant provides safe and appropriate responses.\nPrerequisites Before setting up guardrails, ensure you have:\n✅ Access to Amazon Bedrock console ✅ Appropriate IAM permissions for Bedrock Guardrails ✅ Understanding of your content filtering requirements Access Bedrock Guardrails Console 1. Navigate to Amazon Bedrock\nGo to Amazon Bedrock Console Ensure you\u0026rsquo;re in the us-east-1 region Click Guardrails in the left navigation panel Click Create guardrail button This will start the guardrail configuration wizard 2. Create New Guardrail\nName: slack-ai-assistant-guardrail Description: Guardrail for Slack AI Assistant to filter harmful content and protect sensitive information Configure Content Filters 1. Set Up Harmful Content Filters\nConfigure filters for different types of harmful content:\nHate Speech: High - Block content promoting hatred Insults: Medium - Filter insulting language Sexual Content: High - Block inappropriate sexual content Violence: High - Filter violent content Misconduct: Medium - Block unethical behavior content 2. Set Up Prompt Attacks\nPrompt Attacks: High - Prevent prompt injection attacks\nConfigure Word Filters (Optional) 1. Set Up Profanity Filters\nAdd specific words or phrases to block:\nProfanity Filter: Enable to block common profanity Custom Words: Add company-specific terms to avoid Sensitive Terms: Block internal code names or confidential terms Save ARN and ID Troubleshooting Common Issues 1. Guardrail Creation Fails\nIssue: Permission denied Solution: Verify IAM permissions for Bedrock Guardrails 2. Over-filtering Legitimate Content\nIssue: Too many false positives Solution: Adjust filter levels from High to Medium 3. PII Not Being Detected\nIssue: Sensitive data passing through Solution: Enable additional PII types or use custom regex patterns Best Practice: Start with moderate filtering levels and adjust based on your organization\u0026rsquo;s needs and user feedback.\nNext Steps With your guardrail configured, you\u0026rsquo;re ready to integrate it with your Knowledge Base.\nContinue to: 6.3 Knowledge Base Setup\nSummary In this section, you have:\n✅ Created an Amazon Bedrock Guardrail ✅ Configured content filters for harmful content ✅ Set up PII protection for sensitive information ✅ Tested the guardrail functionality ✅ Prepared for Lambda integration Your AI assistant now has robust safety measures to ensure appropriate and secure responses in your Slack workspace!\n"
},
{
	"uri": "http://localhost:1313/3-slack_app/3.3-oauth_permissions/",
	"title": "Get OAuth Tokens",
	"tags": [],
	"description": "",
	"content": "Configure Bot Permissions Navigate to OAuth \u0026amp; Permissions in your app settings Scroll down to Scopes → Bot Token Scopes and add: commands - Enable slash commands chat:write - Send messages as bot channels:read - Give the bot access to basic information of public channels in the Slack workspace\nInstall App to Workspace Scroll up and click Install to Workspace Review permissions and click Allow Copy OAuth Tokens After installation, you\u0026rsquo;ll see the Bot User OAuth Token (starts with xoxb-) Copy and save this token securely - you\u0026rsquo;ll need it for AWS Lambda configuration Important: Keep your OAuth token secure and never commit it to version control. We\u0026rsquo;ll store it in AWS Secrets Manager later.\nWhat\u0026rsquo;s Next Your Slack app is now fully configured with the necessary permissions and tokens. Next, we\u0026rsquo;ll move on to building the AWS infrastructure that will power your AI assistant.\nContinue to: 4 - Security Configuration\n"
},
{
	"uri": "http://localhost:1313/6-bedrock_setup/6.3-knowledge_base/",
	"title": "Setup Knowledge Base",
	"tags": [],
	"description": "",
	"content": "Create Bedrock Knowledge Base This section guides you through creating a Bedrock Knowledge Base with S3 data source and OpenSearch Serverless integration for your AI assistant.\nS3 Configuration Create S3 Bucket Create a new S3 bucket for storing your documents: Region: us-east-1\nUse default settings for other configurations Bucket name: bucket-bedrock-document868686\nNote ARN\nTip: Use a unique bucket name by including your account ID to avoid naming conflicts.\nConfigure Knowledge Base Access Bedrock Console Navigate to Amazon Bedrock Console\nCreate Knowledge Base Navigate to Knowledge base in the sidebar\nClick Create → Knowledge Base with vector store\nConfigure Knowledge Base Settings Set up the knowledge base configuration:\nBasic Information:\nKnowledge base name: slack-bedrock-kb5 IAM Role: Create a new service role name BedrockKnowledgeBaseRole5\nData Source:\nData source type: Amazon S3\nS3 Configuration:\nSelect your created S3 bucket Use default chunking strategy\nEmbeddings Model:\nSelect Amazon Titan Text Embeddings V2\nVector Store:\nChoose Amazon OpenSearch Serverless\nOpenSearch Configuration:\nCollection: slack-bedrock-vector-db5 (created in Module 5) Vector index name: slack-bedrock-os-index5 Vector field name: bedrock-knowledge-base-default-vector\nText field name: AMAZON_BEDROCK_TEXT_CHUNK Metadata field name:AMAZON_BEDROCK_METADATA\nComplete Creation Create and note the Knowledge Base ID:\nVerify the automatically created IAM role has the necessary policies:\nUpload and Sync Documents Upload Sample Document Upload a sample document to your S3 bucket:\nDownload: PostgreSQL 16 Documentation Upload to your S3 bucket Sync Knowledge Base Sync the Knowledge Base to process the uploaded documents:\nGo to your Knowledge Base Data source Click Sync to start document processing Wait for the sync to complete (may take several minutes) Note: The sync process will chunk your documents, create embeddings using Titan V2, and store them in OpenSearch Serverless for semantic search.\nWhat\u0026rsquo;s Next Your Bedrock Knowledge Base is now configured and ready to answer questions about your uploaded documents. Next, we\u0026rsquo;ll create the Lambda function that will integrate this Knowledge Base with your Slack bot.\nContinue to: 7 Lambda Implementation\n"
},
{
	"uri": "http://localhost:1313/3-slack_app/",
	"title": "Slack App Setup",
	"tags": [],
	"description": "",
	"content": "Overview A Slack app extends Slack\u0026rsquo;s functionality by adding new features, automating tasks, and integrating with external services. For our AI assistant, the Slack app serves as the interface between users and our Amazon Bedrock-powered knowledge base, enabling natural language queries through slash commands.\nWhat You\u0026rsquo;ll Accomplish In this module, you will:\nCreate a new Slack app in your workspace Configure OAuth permissions and slash commands Generate authentication tokens for AWS integration Test the basic app installation Key Components 1. Slack App Configuration\nApp Name: AWS AI Assistant Slash Command: /ask-ai Required Permissions: commands, chat:write, channels:read 2. Authentication Credentials\nBot Token: For API communication (starts with xoxb-) Signing Secret: For request verification Request URL: Will connect to AWS API Gateway Expected Outcome By the end of this module, you\u0026rsquo;ll have a configured Slack app ready to connect with the AWS backend infrastructure we\u0026rsquo;ll build in subsequent modules. The slash command will be visible in your workspace but won\u0026rsquo;t function until we deploy the complete solution.\nContinue to:\n3.1 Create slack app 3.2 Create slash commands 3.3 Get OAuth Tokens "
},
{
	"uri": "http://localhost:1313/4-security/",
	"title": "Configure Security",
	"tags": [],
	"description": "",
	"content": "Security Overview Security is a foundational element of our AI chatbot system, implemented through a dual-layered approach combining AWS Secrets Manager and AWS Systems Manager Parameter Store for secure credential management throughout the application lifecycle.\nWhat You\u0026rsquo;ll Learn In this module, you will understand:\nDual-layer security architecture using AWS Secrets Manager and Parameter Store Secure credential management for Slack authentication tokens IAM best practices for least privilege access Runtime secret resolution without hardcoded values Security Architecture 1. Key Components\nComponent Purpose Security Benefit AWS Secrets Manager Store encrypted Slack credentials Automatic rotation, encryption at rest Parameter Store Runtime secret resolution Dynamic fetching, no hardcoded values IAM Policies Access control Least privilege principle 2. Security Flow\ngraph TB\rA[Lambda Function] --\u0026gt; B[Parameter Store]\rB --\u0026gt; C[Secrets Manager]\rC --\u0026gt; D[Encrypted Slack Credentials]\rE[IAM Policies] --\u0026gt; A\rE --\u0026gt; B\rE --\u0026gt; C\rstyle C fill:#ffebee\rstyle D fill:#f3e5f5\rstyle E fill:#e8f5e8 Security Benefits 1. Separation of Concerns\nSecrets Manager: Handles encryption and secure storage Parameter Store: Manages controlled distribution IAM: Controls access permissions 2. Dynamic Resolution\nCredentials fetched at runtime using {{resolve:secretsmanager:...}} syntax Always up-to-date values without application restarts No hardcoded secrets in source code or environment variables 3. Audit and Compliance\nComplete access traceability through CloudTrail Compliance-ready logging for security audits Monitoring capabilities for unauthorized access attempts 4. Cost Optimization\nStandard-tier Parameter Store parameters Pay-per-use model with no upfront costs No additional encryption charges Implementation Approach The security implementation follows these principles:\nLeast Privilege Access: Lambda functions only access required parameters No Direct Secrets Access: Parameter Store acts as an intermediary layer Encryption at Rest: All secrets encrypted using AWS-managed keys Runtime Resolution: Credentials dynamically resolved during execution Expected Outcomes After implementing this security architecture:\n✅ Slack credentials securely stored and encrypted ✅ Lambda functions access secrets without direct exposure ✅ Complete audit trail for compliance requirements ✅ Production-ready security posture established Continue to: 4.1 Configure AWS Secrets Manager\n"
},
{
	"uri": "http://localhost:1313/5-opensearch/",
	"title": "OpenSearch Serverless",
	"tags": [],
	"description": "",
	"content": "OpenSearch Serverless Overview Amazon OpenSearch Serverless functions as the centralized vector database and memory engine that drives the semantic retrieval capabilities of our Retrieval-Augmented Generation (RAG) workflow. It stores document embeddings and enables high-performance similarity searches for intelligent question answering.\nWhat You\u0026rsquo;ll Learn In this module, you will understand:\nVector database architecture using OpenSearch Serverless Document embedding storage with Amazon Titan Text Embeddings V2 Semantic search capabilities using k-nearest neighbor algorithms Serverless scaling and cost optimization benefits OpenSearch Architecture 1. Vector Storage Flow\ngraph TB\rA[Documents] --\u0026gt; B[Titan Embeddings V2]\rB --\u0026gt; C[Vector Embeddings]\rC --\u0026gt; D[OpenSearch Collection]\rD --\u0026gt; E[Vector Index]\rF[User Query] --\u0026gt; G[Query Embedding]\rG --\u0026gt; H[Similarity Search]\rH --\u0026gt; I[Relevant Chunks]\rstyle D fill:#e8f5e8\rstyle E fill:#fff3e0\rstyle H fill:#e1f5fe 2. Key Components\nComponent Purpose Benefit Vector Collection Store document embeddings Serverless, auto-scaling storage Vector Index Enable similarity search High-performance k-NN algorithms Metadata Storage Preserve document context Traceable retrieval results IAM Integration Security and access control Fine-grained permissions How It Works 1. Document Ingestion\nDocuments processed into high-dimensional vector embeddings Amazon Titan Text Embeddings V2 model creates semantic representations Supports multiple languages including Vietnamese and English Vectors stored in slack-bedrock-vector-db5 collection 2. Vector Indexing\nEmbeddings indexed using slack-bedrock-os-index5 k-nearest neighbor (k-NN) algorithms enable similarity search Metadata preserved for document traceability Sub-second query response times 3. Query Processing\nUser questions embedded using same Titan V2 model Query embedding compared against stored vectors Most relevant document chunks retrieved Context provided to RAG system for response generation Serverless Benefits 1. Auto-Scaling\nAutomatically scales with traffic volume No manual cluster management required Handles varying workloads seamlessly 2. Cost Optimization\nPay-per-use pricing model Predictable costs aligned with usage No upfront infrastructure investment 3. Operational Simplicity\nNo node provisioning or maintenance Fully managed service Built-in high availability Security Features 1. Access Control\nIAM-based permissions with BedrockOSSPolicyForKnowledgeBase Fine-grained access control for authorized components Integration with AWS security services 2. Data Protection\nEncryption at rest and in transit Secure vector storage and retrieval Compliance with enterprise security standards Performance Characteristics Response Time: Sub-second similarity searches Scalability: Automatic scaling based on demand Accuracy: Semantic understanding across languages Reliability: Built-in redundancy and fault tolerance Expected Outcomes After understanding OpenSearch Serverless architecture:\n✅ Vector database serves as persistent memory layer ✅ Semantic search enables intelligent document retrieval ✅ Serverless architecture provides cost-effective scaling ✅ Enterprise security ensures data protection OpenSearch Serverless acts as the intelligent memory of your AI assistant, enabling it to recall and reference organizational knowledge with semantic precision.\nContinue to:\n5.1 OpenSearch Serverless Collection 5.2 Create Vector Index "
},
{
	"uri": "http://localhost:1313/6-bedrock_setup/",
	"title": "Bedrock Setup",
	"tags": [],
	"description": "",
	"content": "Bedrock Setup Overview Amazon Bedrock serves as the core AI engine for our Slack assistant, providing both the foundation models for text generation and the managed Knowledge Base service for Retrieval-Augmented Generation (RAG). This module covers the essential setup required to enable and configure Bedrock services for your AI assistant.\nWhat You\u0026rsquo;ll Learn In this module, you will understand:\nFoundation model access for text generation and embeddings Knowledge Base creation with RAG capabilities S3 integration for document storage and processing IAM roles and permissions for secure Bedrock operations Bedrock Architecture 1. Core Components\ngraph TB\rA[Foundation Models] --\u0026gt; B[Knowledge Base]\rC[S3 Documents] --\u0026gt; B\rB --\u0026gt; D[OpenSearch Serverless]\rB --\u0026gt; E[RAG Responses]\rF[IAM Roles] --\u0026gt; A\rF --\u0026gt; B\rF --\u0026gt; C\rstyle A fill:#fff3e0\rstyle B fill:#e8f5e8\rstyle D fill:#e1f5fe 2. Key Services\nService Purpose Benefit Claude 3 Sonnet Text generation and reasoning High-quality natural language responses Titan Embeddings V2 Document vectorization Semantic understanding and search Knowledge Base RAG orchestration Automated retrieval and generation workflow S3 Integration Document storage Scalable, secure document management Foundation Models 1. Claude 3 Sonnet\nPurpose: Primary text generation model Capabilities: Advanced reasoning, context understanding, multilingual support Use Case: Generating intelligent responses based on retrieved knowledge 2. Amazon Titan Text Embeddings V2\nPurpose: Convert text to vector embeddings Dimensions: 1024-dimensional vectors Languages: Supports multiple languages including English and Vietnamese Use Case: Creating searchable vector representations of documents Knowledge Base Service 1. Managed RAG Workflow\nDocument Ingestion: Automatic processing of S3 documents Chunking Strategy: Intelligent text segmentation for optimal retrieval Vector Storage: Integration with OpenSearch Serverless Retrieval Logic: Semantic similarity search with configurable parameters 2. Benefits\nFully Managed: No infrastructure management required Auto-Scaling: Handles varying document volumes and query loads Security: Built-in encryption and access controls Cost-Effective: Pay-per-use pricing model Expected Outcomes After completing this module setup:\n✅ Foundation models enabled for text generation and embeddings ✅ Knowledge Base configured with S3 document source ✅ RAG workflow operational for intelligent question answering ✅ Secure integration with OpenSearch Serverless established This setup provides the AI intelligence layer that transforms your Slack bot from a simple interface into a knowledgeable assistant capable of understanding and responding to complex queries about your organizational documents.\nContinue to:\n6.1 Model Access Setup 6.2 Set up guardrails 6.3 Set up knowledge base "
},
{
	"uri": "http://localhost:1313/7-lambda_implementation/",
	"title": "Lambda Implementation",
	"tags": [],
	"description": "",
	"content": "Lambda Function Overview The Lambda function serves as the core orchestrator between Slack and Amazon Bedrock Knowledge Base, handling user queries and delivering intelligent responses. It manages the complete interaction flow from Slack command processing to AI-powered response generation.\nWhat You\u0026rsquo;ll Learn In this module, you will understand:\nLambda function architecture for Slack bot integration Asynchronous processing with 3-second acknowledgment requirement Bedrock Knowledge Base integration using RetrieveAndGenerate API Security management with Secrets Manager and Parameter Store Function Architecture Request Flow graph TB\rA[Slack Slash Command] --\u0026gt; B[Lambda Function]\rB --\u0026gt; C[3-Second Acknowledgment]\rB --\u0026gt; D[Retrieve Credentials]\rD --\u0026gt; E[Bedrock RetrieveAndGenerate]\rE --\u0026gt; F[Knowledge Base Query]\rF --\u0026gt; G[AI Response]\rG --\u0026gt; H[Send to Slack]\rstyle B fill:#fff3e0\rstyle E fill:#e8f5e8\rstyle F fill:#e1f5fe Key Components Component Purpose Timing Slack Acknowledgment Prevent timeout errors \u0026lt; 3 seconds Credential Retrieval Secure access to AWS services Initialization Bedrock Integration AI-powered response generation Asynchronous Response Delivery Send results back to Slack After processing Core Functionality 1. Slack Integration\nSlash Command Processing: Handles /ask-ai commands from users 3-Second Rule: Acknowledges requests within Slack\u0026rsquo;s timeout limit Asynchronous Response: Processes queries and responds after acknowledgment 2. Security Management\nAWS Secrets Manager: Retrieves Slack bot tokens securely Parameter Store: Accesses configuration values at runtime IAM Integration: Ensures least privilege access to AWS services 3. AI Processing\nRetrieveAndGenerate API: Queries Bedrock Knowledge Base Semantic Search: Finds relevant document chunks Response Generation: Creates intelligent answers using Claude 3 Sonnet 4. Configuration Management\nModel ID: Specifies Claude 3 Sonnet for text generation Knowledge Base ID: References your created Knowledge Base Guardrail Settings: Ensures safe and appropriate responses Processing Flow Phase 1: Request Handling (\u0026lt; 3 seconds)\nReceive Slack slash command Validate request signature Send acknowledgment to Slack Queue request for processing Phase 2: AI Processing (Asynchronous)\nRetrieve credentials from Parameter Store Initialize Bedrock client Call RetrieveAndGenerate API Process Knowledge Base response Send final answer to Slack Expected Outcomes After implementing the Lambda function:\n✅ Slack commands processed within timeout limits ✅ Secure credential management established ✅ AI-powered responses delivered to users ✅ Complete integration between Slack and Bedrock The Lambda function acts as both orchestrator and executor, ensuring seamless interaction between Slack users and your organization\u0026rsquo;s knowledge base through intelligent AI responses.\nContinue to:\n7.1 Create Lambda Execution Role 7.2 Create and Configure Lambda Function "
},
{
	"uri": "http://localhost:1313/8-api_gateway/",
	"title": "API Gateway Integration and Complete Testing",
	"tags": [],
	"description": "",
	"content": "API Gateway Setup and Testing This final module connects all components together by creating an API Gateway endpoint that receives Slack requests and triggers your Lambda function, then tests the complete AI assistant functionality.\nCreate API Gateway Create REST API\nNavigate to API Gateway Console\nCreate a new REST API:\nAPI Type: REST API API Name: slack-bedrock-api5 Description: API for Slack AI Assistant\nCreate successfully\nCreate Resource Structure\nCreate a resource named slack:\nResource Name: slack Resource Path: / Create a sub-resource named ask-aws:\nParent Resource: /slack Resource Name: ask-ai Resource Path: /slack/ask-ai Configure Method\nCreate a POST method for the ask-ai resource:\nConfigure method settings:\nIntegration Type: Lambda Function Use Lambda Proxy Integration: ✅ Enabled Lambda Function: BedrockKBSlackbotFunction5 Use Default Timeout: ✅ Enabled Method POST created successfully\nNote: Lambda Proxy Integration passes the entire request to Lambda and expects a properly formatted response.\nDeploy API\nDeploy the API to a new stage:\nDeployment Stage: New Stage Stage Name: prod Stage Description: Production deployment Update Slack Configuration\nCopy the Invoke URL from the deployed API:\nFormat: https://your-api-id.execute-api.us-east-1.amazonaws.com/prod/slack/ask-ai Update your Slack app\u0026rsquo;s Slash Commands configuration:\nNavigate to your Slack app settings Go to Slash Commands Update Request URL with the API Gateway invoke URL Click Save Changes Important: The Request URL must exactly match your API Gateway endpoint including the /slack/ask-aws path.\nTesting Your AI Assistant Successful Knowledge Retrieval\nTest Query: Ask a question about content in your uploaded PDF\nCommand: /ask-ai How do i create an index in PostgreSQL and when should i use one? Expected Result: AI assistant retrieves relevant information from the Knowledge Base and provides an accurate answer Command: /ask-aws What are the main data types used in PostgreSQL? Expected Result: AI assistant retrieves relevant information from the Knowledge Base and provides an accurate answer\nGuardrails Protection\nTest Query: Attempt to trigger content filtering Command: /ask-aws How can i hack into a PostgreSQL system? Expected Result: Bedrock Guardrails block the request and return a safety message\nInformation Not Available\nTest Query: AI assistant politely indicates the information is not available in the knowledge base\nCommand: /ask-aws Tell me something inappropriate Expected Result: Ask about content not in your Knowledge Base Testing Checklist Verify your AI assistant handles these scenarios correctly:\n✅ Knowledge Base Queries: Answers questions from uploaded documents ✅ Source Attribution: Provides references to source documents ✅ Unknown Information: Gracefully handles queries outside the knowledge base ✅ Content Safety: Guardrails block inappropriate requests ✅ Response Time: Acknowledges commands within 3 seconds ✅ Error Handling: Provides helpful error messages when issues occur Troubleshooting Common Issues 1. API Gateway Issues\n403 Forbidden: Check Lambda function permissions 502 Bad Gateway: Verify Lambda function response format Timeout: Increase Lambda timeout or check Knowledge Base sync 2. Slack Integration Issues\nCommand Not Found: Verify Request URL matches API Gateway endpoint No Response: Check CloudWatch logs for Lambda errors Permission Denied: Verify Slack app has proper OAuth scopes 3. Knowledge Base Issues\nNo Relevant Results: Ensure documents are properly synced Incorrect Answers: Check document quality and chunking strategy Slow Responses: Monitor OpenSearch Serverless performance Congratulations! 🎉 You have successfully built and deployed a production-ready Generative AI Slack Assistant with:\n✅ Intelligent Question Answering using Amazon Bedrock Knowledge Bases ✅ Enterprise Security with Secrets Manager and Guardrails ✅ Scalable Architecture using serverless AWS services ✅ Real-time Integration with Slack for seamless user experience Your AI assistant is now ready to help users access organizational knowledge through natural language conversations in Slack!\nNext Steps: Continue to: 9. Clear resources\nConsider these enhancements for production deployment:\nAdd more documents to expand the knowledge base Implement user feedback collection for continuous improvement Set up monitoring and alerting for production operations Configure auto-scaling for high-volume usage Add multi-language support for global organizations Workshop Complete! 🚀\n"
},
{
	"uri": "http://localhost:1313/9-clear_resources/",
	"title": "Clear resources",
	"tags": [],
	"description": "",
	"content": "Resource Cleanup This module guides you through properly cleaning up all AWS resources created during the workshop to avoid ongoing charges. Follow the deletion order carefully to prevent dependency errors.\nImportant: Deleting these resources is irreversible. Ensure you have saved any important data or configurations before proceeding.\nCleanup Order Follow this specific order to avoid dependency conflicts:\nDelete API Gateway\nDelete API Gateway:\nNavigate to API Gateway Console Select your slack-bedrock-api5 Click Actions → Delete API Confirm deletion Delete Lambda Function\nDelete Lambda Function:\nNavigate to Lambda Console Select BedrockKBSlackbotFunction5 Click Actions → Delete Confirm deletion Delete Bedrock Knowledge Base\nDelete Knowledge Base:\nNavigate to S3 Console First: Delete all objects in the bucket Then: Delete the bucket itself Confirm deletion\nNavigate to Bedrock Console Go to Knowledge bases Select your knowledge base Click Delete Confirm deletion\nNote: Wait for the Knowledge Base deletion to complete before proceeding to OpenSearch cleanup.\nDelete OpenSearch Serverless Resources\nDelete OpenSearch Components (in this order):\na) Delete Vector Index:\nUse Postman or AWS CLI to delete the index DELETE request to: https://your-collection-endpoint/slack-bedrock-os-index5 b) Delete Collection:\nNavigate to OpenSearch Console Select Collections Delete slack-bedrock-vector-db5 c) Delete Data Access Policy:\nGo to Data access policies Delete your access policy d) Delete Network Policy:\nGo to Network policies Delete your network policy Delete Security Resources\nDelete AWS Secrets Manager Secrets:\nNavigate to Secrets Manager Console Delete slack/bot-token5 Delete slack/signing-secret5 Confirm immediate deletion (skip recovery period) Delete Systems Manager Parameters:\nNavigate to Systems Manager Console Go to Parameter Store Delete /slack/bot-token5/parameter5 Delete /slack/signing-secret5/parameter5 Clean Up IAM Resources\nDelete IAM Role (Optional): Navigate to IAM Console Delete BedrockExecutionRole8888 Delete bedrock-chatbot-deployer user Remove any custom policies created Cost Verification After cleanup, verify no ongoing charges:\nCheck These Services:\n✅ Lambda: No functions remaining ✅ API Gateway: No APIs remaining ✅ OpenSearch Serverless: No collections or policies ✅ S3: No buckets with workshop data ✅ Secrets Manager: No secrets remaining ✅ Bedrock: Knowledge Base deleted (models remain enabled) Tip: Bedrock model access remains enabled but doesn\u0026rsquo;t incur charges unless actively used. You can leave it enabled for future projects.\nCleanup Checklist Confirm all resources are deleted:\n✅ API Gateway deleted ✅ Lambda function deleted ✅ Bedrock Knowledge Base deleted ✅ OpenSearch collection and policies deleted ✅ Secrets Manager secrets deleted ✅ Parameter Store parameters deleted ✅ S3 bucket and contents deleted ✅ IAM roles and users deleted (optional) Final Verification Check AWS Billing Dashboard:\nVerify no unexpected charges Monitor for 24-48 hours after cleanup Review CloudWatch Logs:\nLog groups may remain but don\u0026rsquo;t incur significant costs Delete if desired: /aws/lambda/BedrockKBSlackbotFunction5 Workshop Summary Congratulations on completing the Generative AI Slack Assistant workshop! You have successfully:\n✅ Built an enterprise-grade AI assistant ✅ Implemented RAG architecture with Amazon Bedrock ✅ Configured secure credential management ✅ Deployed serverless infrastructure ✅ Integrated with Slack for real-world usage ✅ Properly cleaned up resources Next Steps Continue to: 10. Conclusion\nConsider these follow-up activities:\nExplore Advanced Features: Guardrails customization, multi-modal inputs Scale the Solution: Multiple knowledge bases, user personalization Production Deployment: CI/CD pipelines, monitoring, alerting Cost Optimization: Reserved capacity, usage analytics Thank you for participating in this workshop! 🎉\nWorkshop Complete - All resources cleaned up successfully!\n"
},
{
	"uri": "http://localhost:1313/10-conclusion/",
	"title": "Conclusion",
	"tags": [],
	"description": "",
	"content": "Workshop Conclusion Congratulations on successfully completing the Generative AI Slack Assistant with Amazon Bedrock Knowledge Bases workshop! You have built a production-ready AI assistant that transforms how organizations access and utilize their knowledge through natural language conversations.\nWhat You\u0026rsquo;ve Accomplished Throughout this comprehensive workshop, you have:\n1. Built Enterprise Architecture\nDeployed a complete serverless AI solution using AWS managed services Implemented Retrieval-Augmented Generation (RAG) with Amazon Bedrock Knowledge Bases Created a scalable, cost-effective architecture that handles varying workloads 2. Implemented Enterprise Security\nConfigured secure credential management with AWS Secrets Manager and Parameter Store Set up content filtering and safety measures using Amazon Bedrock Guardrails Applied least privilege access principles with IAM roles and policies 3. Developed Intelligent Capabilities\nIntegrated Claude 3 Sonnet for advanced natural language understanding Utilized Amazon Titan Text Embeddings V2 for semantic document search Created a knowledge base that understands context and provides accurate responses 4. Achieved Seamless Integration\nConnected Slack with AWS services through API Gateway and Lambda Handled asynchronous processing with proper acknowledgment patterns Delivered real-time responses to users in their familiar Slack environment Key Technical Skills Gained Amazon Bedrock: Foundation model integration and Knowledge Base management OpenSearch Serverless: Vector database operations and semantic search AWS Lambda: Serverless function development and event-driven architecture API Gateway: RESTful API design and Slack webhook integration Security Management: Secrets handling and enterprise-grade access control Business Impact Your AI assistant delivers measurable business value:\nImproved Productivity: Instant access to organizational knowledge Reduced Support Load: Self-service capabilities for common questions Enhanced Collaboration: Shared knowledge accessible to all team members Scalable Solution: Grows with your organization\u0026rsquo;s needs Architecture Highlights The solution you\u0026rsquo;ve built demonstrates modern cloud architecture principles:\nServerless-First: No infrastructure management required Event-Driven: Responsive to user interactions Secure by Design: Enterprise-grade security throughout Cost-Optimized: Pay-per-use pricing model Highly Available: Built-in redundancy and fault tolerance Future Enhancements Consider these next steps to expand your AI assistant:\n1. Advanced Features\nMulti-language support for global organizations Custom guardrails for industry-specific content filtering Integration with additional data sources (databases, APIs, wikis) User personalization and conversation history 2. Production Optimization\nCI/CD pipeline for automated deployments Advanced monitoring and alerting with CloudWatch Performance optimization and caching strategies Multi-region deployment for global availability 3. Extended Integrations\nMicrosoft Teams and other collaboration platforms Voice interfaces with Amazon Alexa for Business Mobile applications with direct API access Integration with existing enterprise systems Learning Resources Continue your AI and AWS journey with these resources:\nAWS Documentation: Amazon Bedrock User Guide AWS Training: Machine Learning on AWS Community: AWS AI/ML Community Certification: AWS Certified Machine Learning - Specialty Final Thoughts You\u0026rsquo;ve successfully transformed static organizational knowledge into an intelligent, conversational assistant that employees can interact with naturally. This workshop has equipped you with the skills to build, deploy, and maintain enterprise-grade AI solutions using AWS managed services.\nThe future of workplace productivity lies in making information instantly accessible through natural language interfaces. You\u0026rsquo;re now prepared to lead this transformation in your organization.\nCredits This workshop was developed and maintained by:\nLe Hong Anh\nAI Solutions Architect\nLinkedIn Profile\nTran Doan Cong Ly\nCloud Solutions Engineer\nLinkedIn Profile\nReferences 1. AWS Documentation\nAmazon Bedrock Developer Guide Amazon Bedrock Knowledge Bases Amazon OpenSearch Serverless AWS Lambda Developer Guide Amazon API Gateway Developer Guide 2. Slack Development\nSlack Bolt for Python Slack API Documentation Slack App Development 3. AI and Machine Learning\nRetrieval-Augmented Generation (RAG) Overview Foundation Models on Amazon Bedrock Vector Databases and Semantic Search 4. Security Best Practices\nAWS Security Best Practices AWS Secrets Manager Best Practices IAM Best Practices 5. Blog Posts and Articles\nCreate a generative AI assistant with Slack and Amazon Bedrock Building RAG Applications with Amazon Bedrock Serverless AI Applications on AWS Thank you for participating in this workshop! 🎉\nWe hope this experience has inspired you to continue exploring the possibilities of generative AI and AWS cloud services. Your feedback and success stories help us improve future workshops and support the growing AI community.\nHappy building! 🚀\n"
},
{
	"uri": "http://localhost:1313/categories/",
	"title": "Categories",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "http://localhost:1313/tags/",
	"title": "Tags",
	"tags": [],
	"description": "",
	"content": ""
}]